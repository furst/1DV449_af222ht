# Reflektion

## 1
Jag valde att jobba med Node.js, Phantom.js och Jquery för att lösa uppgiften. Har aldrig jobbat med scraping tidigare men jag fick för mig att det borde vara lättast att använda javascript för komma åt dom-elementen. Nu kan jag inte jämföra hur snabbt det hade gått om jag hade använt php men det kändes rätt smidigt när jag väl hade lört mig node.js som jag aldrig har jobbat med tidigare. Node.js är javascript som körs på serversidan.

## 2
* Elementen som skrapas kan lätt ändras och då kraschar applikationen
* Data kan bytas ut mot skräp och farlig kod
* Om man skrapar saker som är copyright-skyddade kan man råka illa ut

## 3
Inga, då jag öppnar en virtuell webbläsare så sköts sessionhantering etc. av den.
Men det kan annars bli problem med det gömde fältet i formulär skulle jag tro.

# 4
Nej, jag kunde kanske ha frågat om lov. Men recepten är inte skyddade.

# 5
Node.js har jag lärt mig, en mycket intressant serverlösning!
Skrapning är kul och jag skulle även kunna bygga automatiska testfall som klickar igenom sidor.
Blivit en bättre programmerare i allmänhet
En mycket bra uppgift!